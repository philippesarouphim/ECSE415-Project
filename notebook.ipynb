{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECSE 415 - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from typing import Generator\n",
    "from cv2.typing import MatLike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a `PATH` variable that points to the repository. Every memory access in the code will be relative to that variable.\n",
    "\n",
    "We also define a few functions that will be useful throughout the code:\n",
    "- `showImages`: This function displays a grid of images with their titles.\n",
    "- `showGSImages`: This function displays a grid of grayscale images with their titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./\"\n",
    "\n",
    "np.set_printoptions(edgeitems=24)\n",
    "\n",
    "def showImages(images, titles):\n",
    "    '''This function takes a 2D array of images and titles and displays them in the notebook in color'''\n",
    "    rows = len(images)\n",
    "    cols = len(images[0])\n",
    "    fig = plt.figure(figsize=(cols * 7 if cols > 1 else 12, rows * 5))\n",
    "\n",
    "    # Add every picture in the plot\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if images[i][j] is None: continue\n",
    "            fig.add_subplot(rows, cols, i * cols + j + 1)\n",
    "            plt.imshow(images[i][j][:,:,::-1])\n",
    "            plt.axis('off')\n",
    "            plt.title(titles[i][j])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def showGSImages(images, titles, cmap=[]):\n",
    "    '''This function takes a 2D array of images and titles and displays them in the notebook in grayscale'''\n",
    "    rows = len(images)\n",
    "    cols = len(images[0])\n",
    "    fig = plt.figure(figsize=(cols * 7 if cols > 1 else 12, rows * 5))\n",
    "\n",
    "    # Add every picture in the plot\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if images[i][j] is None: continue\n",
    "            fig.add_subplot(rows, cols, i * cols + j + 1)\n",
    "            plt.imshow(images[i][j], cmap=cmap[i][j] if len(cmap) != 0 else 'gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(titles[i][j])\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Video Reader\n",
    "\n",
    "We define a `VideoReader` class that helps with reading video from the filesystem.\n",
    "\n",
    "It is based on OpenCV's `VideoCapture` class, and helps with reading the frames of a video, as well as getting information such as the frame dimension and the FPS value.\n",
    "\n",
    "The main purpose of this class is to wrap the functionalities needed to read every nth frame of a video using the `VideoReader.frames(n)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoReader():\n",
    "    \"\"\"\n",
    "    A class used to read videos from the filesystem.\n",
    "    \n",
    "    ---\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    `filename` : `str`\n",
    "        A string pointing to the path of the video in the file system.\n",
    "    \n",
    "    `cap` : `VideoCapture`\n",
    "        The underlying OpenCV `VideoCapture` that helps read the video file.\n",
    "\n",
    "    `framewidth` : `int`\n",
    "        An integer indicating the width of the frames in the video.\n",
    "\n",
    "    `frameheight` : `int`\n",
    "        An integer indicating the height of the frames in the video.\n",
    "    \n",
    "    `fps` : `float`\n",
    "        A floating-point number indicating the framerate of the video.\n",
    "\n",
    "    ---\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    `getInfo() -> (int, int, float)`\n",
    "        Get basic information about the video: frame width, frame height, frame rate.\n",
    "\n",
    "    `frames(freq: int) -> Generator[MatLike, None, None]`\n",
    "        Generator function that yields every nth frame.\n",
    "\n",
    "    `release()`\n",
    "        Video capture release.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filename: str):\n",
    "        # Open video\n",
    "        self.cap = cv2.VideoCapture(filename)\n",
    "\n",
    "        # Ensure video was correctly opened or raise exception\n",
    "        if(self.cap.isOpened() == False):\n",
    "            raise SystemExit(\"Error opening video file!\")\n",
    "        \n",
    "        # Get basic information of video\n",
    "        self.frame_width = int(self.cap.get(3))\n",
    "        self.frame_height = int(self.cap.get(4))\n",
    "        self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    \n",
    "    def getInfo(self) -> (int, int, float):\n",
    "        \"\"\"\n",
    "        Get basic information about the video: frame width, frame height, frame rate.\n",
    "\n",
    "        ---\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `int`\n",
    "            Frame width\n",
    "\n",
    "        `int`\n",
    "            Frame height\n",
    "            \n",
    "        `float`\n",
    "            Frame rate\n",
    "        \"\"\"\n",
    "        return self.frame_width, self.frame_height, self.fps\n",
    "    \n",
    "\n",
    "    def frames(self, freq: int) -> Generator[MatLike, None, None]:\n",
    "        \"\"\"\n",
    "        Generator function that yields every nth frame of the video.\n",
    "\n",
    "        ---\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        `freq`: `int`\n",
    "            Integer representing the number of frames to skip before yielding the next one.\n",
    "        \n",
    "        ---\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        `MatLike`\n",
    "            Next frame of the video.\n",
    "        \"\"\"\n",
    "        i = 0\n",
    "        while(self.cap.isOpened()):\n",
    "            ret, frame = self.cap.read()\n",
    "            \n",
    "            # If end of video is reached, exit the generator loop\n",
    "            if ret == False: break\n",
    "\n",
    "            i += 1\n",
    "            # Skip frame if its index is not a multiple of freq\n",
    "            if i % freq != 0: continue\n",
    "\n",
    "            yield frame\n",
    "    \n",
    "    \n",
    "    def release(self):\n",
    "        \"\"\"\n",
    "        Function that releases the `VideoCapture` element that helped read the video.\n",
    "        \"\"\"\n",
    "        self.cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundingBox():\n",
    "    \"\"\"\n",
    "    A class that is used to represent a bounding box detected by object detector models.\n",
    "\n",
    "    ---\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    `x`: `float`\n",
    "        Float representing the x-coordinate of the top-left corner of the bounding box.\n",
    "    \n",
    "    `y`: `float`\n",
    "        Float representing the y-coordinate of the top-left corner of the bounding box.\n",
    "    \n",
    "    `w`: `float`\n",
    "        Float representing the width of the bounding box.\n",
    "    \n",
    "    `h`: `float`\n",
    "        Float representing the height of the bounding box.\n",
    "    \n",
    "    `clazz`: `int`\n",
    "        Class ID of the detected object.\n",
    "    \n",
    "    `confidence`: `float`\n",
    "        Float between 0 and 1 representing the classification confidence of the object in the\n",
    "        bounding box.\n",
    "    \n",
    "    `center_x`: `float`\n",
    "        Float representing the x-coordinate of the center point of the bounding box.\n",
    "    \n",
    "    `center_y`: `float`\n",
    "        Float representing the y-coordinate of the center point of the bounding box.\n",
    "    \n",
    "    ---\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    `get_distance(other: BoundingBox)`\n",
    "        This function computes the distance between the center point of this bounding box and the\n",
    "        center point of another bounding box.\n",
    "    \n",
    "    `get_top_left_corner() -> (int, int)`\n",
    "        This function returns a tuple holding the rounded coordinates of the top-left corner of the\n",
    "        bounding box.\n",
    "    \n",
    "    `get_lower_right_corner() -> (int, int)`\n",
    "        This function returns a tuple holding the rounded coordinates of the lower-right corner of\n",
    "        the bounding box.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, x: float, y: float, w: float, h: float, clazz: int, confidence: float):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        self.clazz = clazz\n",
    "        self.confidence = confidence\n",
    "\n",
    "        # Compute center coordinates of the bounding box\n",
    "        self.center_x = x + w / 2\n",
    "        self.center_y = y + h / 2\n",
    "    \n",
    "\n",
    "    def get_distance(self, other: \"BoundingBox\") -> float:\n",
    "        \"\"\"\n",
    "        This function computes the distance between the center point of this bounding box and the\n",
    "        center point of another bounding box.\n",
    "\n",
    "        ---\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        `other`: `BoundingBox`\n",
    "            The other bounding box with which to compute the distance.\n",
    "        \n",
    "        ---\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `float`\n",
    "            Distance between this bounding box and the other.\n",
    "        \"\"\"\n",
    "        return np.sqrt((self.center_x - other.center_x) ** 2 + (self.center_y - other.center_y) ** 2)\n",
    "\n",
    "\n",
    "    def get_top_left_corner(self) -> (int, int):\n",
    "        \"\"\"\n",
    "        This function returns a tuple holding the rounded coordinates of the top-left corner of the\n",
    "        bounding box.\n",
    "\n",
    "        ---\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `(int, int)`\n",
    "            Tuple of the rounded coordinates (x, y) of the top-left corner of the bounding box.\n",
    "        \"\"\"\n",
    "        return (round(self.x), round(self.y))\n",
    "    \n",
    "\n",
    "    def get_lower_right_corner(self) -> (int, int):\n",
    "        \"\"\"\n",
    "        This function returns a tuple holding the rounded coordinates of the lower-right corner of \n",
    "        the bounding box.\n",
    "\n",
    "        ---\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `(int, int)`\n",
    "            Tuple of the rounded coordinates (x, y) of the lower-right corner of the bounding box.\n",
    "        \"\"\"\n",
    "        return (round(self.x + self.w), round(self.y + self.h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Object():\n",
    "    \"\"\"\n",
    "    A class that represents an object in the video.\n",
    "\n",
    "    ---\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    `id`: `int`\n",
    "        Unique ID of the object in the video.\n",
    "    \n",
    "    `bounding_box`: `BoundingBox`\n",
    "        The bounding box of the object in the video. This is updated every frame.\n",
    "    \n",
    "    `absent_frames`: `int`\n",
    "        The number of frames since the object disappeared from the scene.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, id: int, bounding_box: BoundingBox):\n",
    "        self.id = id\n",
    "        self.bounding_box = bounding_box\n",
    "        self.absent_frames = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo:\n",
    "    \"\"\"\n",
    "    A class that contains a YOLOv3 model pretrained on the COCO dataset.\n",
    "    It wraps the functionalities to process a picture on this model and retrieve the bounding boxes\n",
    "    of the detected and classified objects.\n",
    "\n",
    "    ---\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    `yolov3`: `Net`\n",
    "        YOLOv3 neural network pretrained on the COCO dataset.\n",
    "\n",
    "    `classes`: `list[str]`\n",
    "        List of classes that can be classified by the model.\n",
    "    \n",
    "    `colors`: `ndarray[Any, dtype[float64]]`\n",
    "        Randomly-generated RGB tuples list where each tuple represents the color associated to a\n",
    "        class. For the purposes of drawing the bounding boxes.\n",
    "    \n",
    "    ---\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    `process_frame(frame: MatLike) -> list[BoundingBox]`\n",
    "        This function processes an image using the model and returns a list of the resulting\n",
    "        bounding boxes.\n",
    "    \n",
    "    `draw_bounding_box(img: MatLike, obj: Object)`\n",
    "        This function draws a given object and its associated bounding box on a given image.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Import Darknet Yolov3 CNN from file as well as weights from COCO pretraining\n",
    "        self.yolov3 = cv2.dnn.readNet(PATH + \"/data/yolov3.weights\", PATH + \"/data/yolov3.cfg\")\n",
    "\n",
    "        # Import COCO classes from file\n",
    "        self.classes = []\n",
    "        classes_file = open(PATH + \"/data/yolov3.classes\", \"r\")\n",
    "        for l in classes_file.readlines():\n",
    "            self.classes.append(l.strip())\n",
    "\n",
    "        # Generate random colors for each class to draw bounding boxes\n",
    "        self.colors = np.random.uniform(0, 255, size=(len(self.classes), 3))\n",
    "    \n",
    "    \n",
    "    def process_frame(self, frame: MatLike) -> list[BoundingBox]:\n",
    "        \"\"\"\n",
    "        This function processes an image using the model and returns a list of the resulting\n",
    "        bounding boxes.\n",
    "\n",
    "        ---\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        `frame`: `MatLike`\n",
    "            Image to be processed by the model.\n",
    "        \n",
    "        ---\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `list[BoundingBox]`\n",
    "            The list of bounding boxes found by the model.\n",
    "        \"\"\"\n",
    "        frame_blob = cv2.dnn.blobFromImage(frame, 0.00392, (416,416), (0,0,0), True, crop=False)\n",
    "\n",
    "        # Execute neural network with image as input\n",
    "        self.yolov3.setInput(frame_blob)\n",
    "        output = self.yolov3.forward()\n",
    "\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "\n",
    "        CONF_THRESH = 0.5\n",
    "        # Extract data from output matrix\n",
    "        for o in output:\n",
    "            # Get predicted class and confidence for bounding box\n",
    "            scores = o[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            # Consider bounding box only if confidence is above threshold value\n",
    "            if confidence > CONF_THRESH:\n",
    "                center_x = int(o[0] * frame.shape[1])\n",
    "                center_y = int(o[1] * frame.shape[0])\n",
    "                w = int(o[2] * frame.shape[1])\n",
    "                h = int(o[3] * frame.shape[0])\n",
    "                x = center_x - w / 2\n",
    "                y = center_y - h / 2\n",
    "                class_ids.append(class_id)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([x, y, w, h])\n",
    "\n",
    "        # Apply non-max suppression\n",
    "        NMS_THRESH = 0.4\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, CONF_THRESH, NMS_THRESH)\n",
    "\n",
    "        # Create the bounding box objects\n",
    "        bounding_boxes = []\n",
    "        for idx in indices:\n",
    "            bounding_boxes.append(BoundingBox(boxes[idx][0], boxes[idx][1], boxes[idx][2], boxes[idx][3], class_ids[idx], confidences[idx]))\n",
    "\n",
    "        return bounding_boxes\n",
    "\n",
    "\n",
    "    # function to draw bounding box on the detected object with class name\n",
    "    def draw_bounding_box(self, img: MatLike, obj: Object):\n",
    "        \"\"\"\n",
    "        This function draws a given object and its associated bounding box on a given image.\n",
    "\n",
    "        ---\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        `img`: `MatLike`\n",
    "            Image on which to draw the object and its bounding box.\n",
    "        \n",
    "        `obj`: `Object`\n",
    "            Object to draw on the image.\n",
    "        \"\"\"\n",
    "        label = \"{} {} (#{})\".format(self.classes[obj.bounding_box.clazz], round(obj.bounding_box.confidence, 2), obj.id)\n",
    "        color = self.colors[obj.bounding_box.clazz]\n",
    "        cv2.rectangle(img, obj.bounding_box.get_top_left_corner(), obj.bounding_box.get_lower_right_corner(), color, 2)\n",
    "        cv2.putText(img, label, (round(obj.bounding_box.x - 10), round(obj.bounding_box.y - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE_THRESHOLD = 75\n",
    "MAX_ABSENT_FRAMES = 5\n",
    "\n",
    "class Objects():\n",
    "    \"\"\"\n",
    "    A class that contains the objects present in the scene and the necessary logic to track objects\n",
    "    across frames.\n",
    "\n",
    "    ---\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    `idx`: `int`\n",
    "        Integer iterator that tracks the next unique ID that can be given to a new object.\n",
    "    \n",
    "    `objects`: `dict[int, list[Object]]`\n",
    "        Dictionary contianing lists of objects categorized by their class.\n",
    "    \n",
    "    ---\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    `add_frame(bbs: list[BoundingBox])`\n",
    "        This function takes in the bounding boxes of the next frame and matches the existing objects\n",
    "        to the new bounding boxes. It updates the the matched objects, creates new objects for new\n",
    "        bounding boxes, and removes objects that no longer exist, when appropriate.\n",
    "    \n",
    "    `compute_distances(clazz: int, bbs: list[BoundingBox]) -> dict[tulpe[Object, BoundingBox], float]`\n",
    "        This function computes all the distances between the objects in the class's dictionary that\n",
    "        correspond to the input class ID, and the input bounding boxes.\n",
    "    \n",
    "    `match_bounding_boxes(distances: dict[tuple[Object, BoundingBox], float]) -> (list[tuple[Object, BoundingBox]], list[Object], list[BoundingBox])`\n",
    "        This function finds the matches between the existing objects in the scene and the input\n",
    "        bounding boxes.\n",
    "    \n",
    "    `next_id() -> int`\n",
    "        This function increments `idx` and returns the new value. This serves when creating a new\n",
    "        object.\n",
    "    \n",
    "    `get_all_objects() -> list[Object]`\n",
    "        This function returns a list of all objects in the scene by flattening the dictionary\n",
    "        values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.idx = -1\n",
    "        self.objects: dict[int, list[Object]] = dict({})\n",
    "\n",
    "\n",
    "    def add_frame(self, bbs: list[BoundingBox]):\n",
    "        \"\"\"\n",
    "        This function takes in the bounding boxes of the next frame and matches the existing objects\n",
    "        to the new bounding boxes. It updates the the matched objects, creates new objects for new\n",
    "        bounding boxes, and removes objects that no longer exist, when appropriate.\n",
    "\n",
    "        ---\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        `bbs`: `list[BoundingBox]`\n",
    "            The new bounding boxes found in the next frame.\n",
    "        \"\"\"\n",
    "        # For each objects of a given class\n",
    "        for c in self.objects.keys():\n",
    "            # Find the matches with the new bounding boxes\n",
    "            bbs_c = list(filter(lambda bb: bb.clazz == c, bbs))\n",
    "            distances = self.compute_distances(c, bbs_c)\n",
    "            matches, used_objs, used_bbs = self.match_bounding_boxes(distances)\n",
    "\n",
    "            # Eliminate matches that excees the distance threshold\n",
    "            for match in matches:\n",
    "                if distances[match] > (match[0].absent_frames + 1) * DISTANCE_THRESHOLD:\n",
    "                    used_objs.remove(match[0])\n",
    "                    used_bbs.remove(match[1])\n",
    "                    matches.remove(match)\n",
    "\n",
    "            # Increment the absent_frames attribute of all objects that do not appear in the new\n",
    "            # frame\n",
    "            for obj in self.objects[c]:\n",
    "                if not obj in used_objs:\n",
    "                    obj.absent_frames += 1\n",
    "\n",
    "                    if obj.absent_frames > MAX_ABSENT_FRAMES:\n",
    "                        self.objects[c].remove(obj)\n",
    "            \n",
    "            # Create a new object for every bounding box that was not present in the previous frames\n",
    "            for bb in bbs_c:\n",
    "                if not bb in used_bbs:\n",
    "                    self.objects[c].append(Object(self.next_id(), bb))\n",
    "\n",
    "            # Update the bounding boxes of the matched objects\n",
    "            for match in matches:\n",
    "                match[0].bounding_box = match[1]\n",
    "                match[0].absent_frames = 0\n",
    "        \n",
    "        # For every bounding box whose class was not previously present in the dictionary:\n",
    "        # 1. Add a new list entry to the dictionary\n",
    "        # 2. Create a new object for the bounding box\n",
    "        # 3. Append the new object to the dictionary\n",
    "        for bb in list(filter(lambda bb: (not bb.clazz in self.objects), bbs)):\n",
    "            if bb.clazz not in self.objects: self.objects[bb.clazz] = []\n",
    "            self.objects[bb.clazz].append(Object(self.next_id(), bb))\n",
    "\n",
    "\n",
    "    def compute_distances(self, clazz: int, bbs: list[BoundingBox]) -> dict[tuple[Object, BoundingBox], float]:\n",
    "        \"\"\"\n",
    "        This function computes all the distances between the objects in the class's dictionary that\n",
    "        correspond to the input class ID, and the input bounding boxes.\n",
    "\n",
    "        ---\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        `clazz`: `int`\n",
    "            Class ID whose objects to get from the class's dictionary.\n",
    "        \n",
    "        `bbs`: `list[BoundingBox]`\n",
    "            Bounding boxes to compute the distances with. These should also be of the class `clazz`.\n",
    "        \n",
    "        ---\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `dict[tuple[Object, BoundingBox], float]\n",
    "            Dictionary mapping each object-bounding box pair to the distance that separates them.\n",
    "        \"\"\"\n",
    "        distances: dict[tuple[Object, BoundingBox], float] = dict({})\n",
    "\n",
    "        # Compute distances between all objects and all bounding boxes\n",
    "        for obj in self.objects[clazz]:\n",
    "            for bb in bbs:\n",
    "                distances[(obj, bb)] = obj.bounding_box.get_distance(bb)\n",
    "\n",
    "        return distances\n",
    "\n",
    "\n",
    "    def match_bounding_boxes(self, distances: dict[tuple[Object, BoundingBox], float]) -> (list[tuple[Object, BoundingBox]], list[Object], list[BoundingBox]):\n",
    "        \"\"\"\n",
    "        This function finds the matches between the existing objects in the scene and the input\n",
    "        bounding boxes.\n",
    "\n",
    "        ---\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        `distances`: `dict[tuple[Object, BoundingBox], float]`\n",
    "            Dictionary mapping each object-bounding box pair to the distance that separates them.\n",
    "        \n",
    "        ---\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `list[tuple[Object, BoundingBox]]`\n",
    "            List of object-bounding box pairs representing the matches. Each object and bounding box\n",
    "            appears only once in the list.\n",
    "        \n",
    "        `list[Object]`\n",
    "            List of matched objects.\n",
    "\n",
    "        `list[BoundingBox]`\n",
    "            List of matched bounding boxes.\n",
    "        \"\"\"\n",
    "        # Sort the distances dictionary\n",
    "        sorted_keys = list(sorted(distances, key=distances.get))\n",
    "\n",
    "        mutex_keys = []\n",
    "        used_objs = set([])\n",
    "        used_bbs = set([])\n",
    "        for k in sorted_keys:\n",
    "            # If object or bounding box is already match, skip entry\n",
    "            if k[0] in used_objs or k[1] in used_bbs: continue\n",
    "\n",
    "            # Mark the matched object and bounding box as used\n",
    "            used_objs.add(k[0])\n",
    "            used_bbs.add(k[1])\n",
    "\n",
    "            # Append the pair to the list of matches\n",
    "            mutex_keys.append(k)\n",
    "\n",
    "        return mutex_keys, used_objs, used_bbs\n",
    "\n",
    "\n",
    "    def next_id(self) -> int:\n",
    "        \"\"\"\n",
    "        This function increments `idx` and returns the new value. This serves when creating a new\n",
    "        object.\n",
    "\n",
    "        ---\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `int`\n",
    "            The unique ID to use for the new object.\n",
    "        \"\"\"\n",
    "        self.idx += 1\n",
    "        return self.idx\n",
    "    \n",
    "\n",
    "    def get_all_objects(self) -> list[Object]:\n",
    "        \"\"\"\n",
    "        This function returns a list of all objects in the scene by flattening the dictionary\n",
    "        values.\n",
    "\n",
    "        ---\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `list[Object]`\n",
    "            The list of all objects in the scene.\n",
    "        \"\"\"\n",
    "        return  [value for sublist in self.objects.values() for value in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame dimensions: (2562, 1440)\n",
      "FPS: 29.97002997002997\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "yolo = Yolo()\n",
    "\n",
    "# Create the video reader\n",
    "video_in = VideoReader(PATH + \"/data/mcgill_drive.mp4\")\n",
    "\n",
    "# Get basic information on video and print them\n",
    "frame_width, frame_height, fps = video_in.getInfo()\n",
    "print(\"Frame dimensions: ({}, {})\".format(frame_width, frame_height))\n",
    "print(\"FPS: {}\".format(fps))\n",
    "\n",
    "# Create the output video stream\n",
    "out = cv2.VideoWriter(PATH + \"/out/mcgill_drive.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width,frame_height))\n",
    "\n",
    "# Create the object that holds all objects in the scene\n",
    "objects = Objects()\n",
    "\n",
    "# Loop over every frame\n",
    "for frame in video_in.frames(1):\n",
    "    # Process frame and process new bounding boxes for tracking\n",
    "    bounding_boxes = yolo.process_frame(frame)\n",
    "    objects.add_frame(bounding_boxes)\n",
    "    \n",
    "    # Draw each object on the frame picture\n",
    "    for obj in objects.get_all_objects():\n",
    "        yolo.draw_bounding_box(frame, obj)\n",
    "    \n",
    "    # Write the new frame picture with bounding boxes to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "\n",
    "# Release video streams\n",
    "video_in.release()\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
